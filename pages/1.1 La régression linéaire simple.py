import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
plt.rcParams.update(plt.rcParamsDefault)
from scipy import stats
import numpy as np

st.set_page_config(
    page_icon="üêç",
)
st.markdown("<h1 style='text-align: center; color: black;'>La r√©gression lin√©aire</h1>", unsafe_allow_html=True)

st.image("https://miro.medium.com/max/1200/0*MkEov3K6UUjhuwOd.jpeg")

st.markdown("Ce chapitre introduit la notion de mod√®le lin√©aire par la version la plus √©l√©mentaire : _**expliquer $Y$ par une fonction affine de $X$**_.")

st.markdown("""
# La r√©gression lin√©aire simple
La r√©gression lin√©aire est simple lorsque le mod√®le ne comporte qu'_une variable explicative_ $X$.
##### Exemple : Pr√©dire le prix du loyer d'un logement :
""")
d = {'Taille en m¬≤ (X)': [55, 110, 60, 75,150  ], 'Prix en 1000‚Ç¨ (Y)': [195000, 305000, 205000, 280000, 370000]}
df = pd.DataFrame(d)


# CSS to inject contained in a string
hide_table_row_index = """
            <style>
            thead tr th:first-child {display:none}
            tbody th {display:none}
            </style>
            """

# Inject CSS with Markdown
st.markdown(hide_table_row_index, unsafe_allow_html=True)

# Display a static table
st.table(df)


st.markdown("""
Repr√©sentation graphique du prix d'appartements en fonction de la surface en m¬≤
""")

x = [55, 110, 60, 75,150  ]
y = [195000, 305000, 205000, 280000, 370000]

fig = plt.figure()
plt.scatter(x, y)
# plt.plot(x, y)
st.pyplot(fig)


st.markdown(r"""
Notons : 
- $X$ pour la taille du logement, c'est la **variable explicative** (feature)
- $Y$ pour le Prix en ‚Ç¨, c'est la **variable √† expliquer** (cible ou target)
- $m$ pour le nombre d'exemples (logements) d'entra√Ænement (training examples)
- $n$ pour lr nombre de variables
- Une paire $(x^{(i)},y^{(i)})$ est appel√©e **training example**
- l'ensemble de donn√©es que nous allons utiliser $${(x^{(i)},y^{(i)}), i = 1,2,3,...}$$ (une liste de $m$ exemples de raining examples) est appel√© un **training set**, Les variables de la $2$√®me observation, par exemple, sont not√©es $x^{(2)} = 110$ et $y{(2)} = 305000$.



### Qu'est-ce qu'une mod√©lisation ?
C'est un algorithme qui lie une variable explicative (surface en $m^2$) par une variable √† expliquer (le prix en ‚Ç¨). Dans notre cas, notre algorithme est une fonction math√©matique $h$.
La fonction $h$ s'appelle une **hypoth√®se**
""")
st.image("LR1.png")

st.markdown(r"""
Lorsque la variable cible que nous essayons de pr√©dire est continue, comme dans notre exemple de logement,
 nous appelons le probl√®me d'apprentissage un probl√®me de **r√©gression**. 
 Lorsque y ne peut prendre qu'un petit nombre de valeurs discr√®tes (comme si, compte tenu de la surface habitable, nous 
 voulions pr√©dire si un logement est une maison ou un appartement, par exemple), nous appelons cela un probl√®me de **classification**.

### L'hypoth√®se 
est la fonction qui doit √™tre apprise par l'algorithme d'apprentissage par la progression de la formation pour faire les pr√©dictions sur 
les donn√©es invisibles. $h$ is given by :
$$
\hat{y} = h_{\theta}(X) = \theta_0 + \theta_1 X
$$
o√π : 
- $\hat{Y}$ d√©signe la valeur pr√©dite par le mod√®le, √† la diff√©rence du $Y$ normal qui d√©signe la vraie valeur de la variable. L
- a fonction $h_{\theta}$ s'appelle la fonction de pr√©diction (ou d'hypoth√®se), et les valeurs $\theta_0$ et $\theta_1$ s'appellent les param√®tres du mod√®le. On peut √©galement consid√©rer que le mod√®le a un seul param√®tre $\theta$, qui est un vecteur de composantes $(\theta_0, \theta_1)$.
- $\theta_0$ est l'ordonn√©e √† l'origine (intercept) et
- $\theta_0$ est la pente de la droite.
""")

slope, intercept, r, p, std_err = stats.linregress(x, y)

def myfunc(x):
  return slope * x + intercept

mymodel = list(map(myfunc, x))

fig = plt.figure()
plt.scatter(x, y)
plt.plot(x, mymodel)
st.pyplot(fig)

st.markdown(r"""
L'apprentissage consiste ici √† d√©terminer quelles sont les valeurs de Œ∏0 et Œ∏1 qui donnent la meilleure estimation de $Y$. 
Concr√®tement, pour la repr√©sentation graphique, il s'agit de **tracer une droite qui s'approche la plus possible de toutes les observations**.
""")

st.image("fig-2-simple-hypothesis.png")

st.markdown(r"""
### La fonction co√ªt : l‚Äôerreur quadratique moyenne
Pour pr√©ciser ce que signifie une ‚Äúbonne estimation‚Äù de Y, on d√©finit ce qu'on appelle une **fonction d'erreur** (**cost function**),
 qui mesure l'erreur entre les valeurs pr√©dites par le mod√®le et les valeurs oberv√©es. Dans la r√©gression lin√©aire, on utilise la fonction
  d'erreur dite des **moindres carr√©s**, qui a la forme suivante:
$$
J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^m (h_{\theta}(x^{(i)}) - y^{(i)})^2
$$
Cette fonction repr√©sente la sommme sur toutes les observations de la distance (au carr√©) entre la valeur observ√©e de $Y$ et sa valeur pr√©dite par le mod√®le $h_{\theta}(x^{(i)})$.
Comme le but est que l'erreur (Distance entre les observations et les pr√©dictions) soit globalement la plus petite possible, le probl√®me revient √† **minimiser** la fonction d'erreur $J$, 
c'est-√†-dire √† trouver le param√®tre $\theta$ pour lequel la valeur $J(\theta_0,\theta_1)$ est minimale.
- Le terme m sert √† faire la moyenne
- Le terme $\frac{1}{2}$ est ajout√© comme une astuce afin de faciliter les calculs de la descente du gradient par la suite.

Cette fonction est appel√©e **Mean Squared Error (MSE)**, **Squared Error function** et en fran√ßais on parlera plut√¥t de la **m√©thode des moindres carr√©s* (ou encore l'**erreur quadratique moyenne**)

Ce qu'il y a de fascinant, c'est que ce probl√®me est r√©sum√© √† un seul r√©sultat, la valeur de la fonction co√ªt. Si on minimise cette fonction co√ªt, on trouvera les meilleurs param√®tres $\theta$ et donc la mod√©lisation la plus performante.


### Rappel : qu‚Äôest-ce que la d√©riv√©e d‚Äôune fonction ?
Graphiquement, la d√©riv√©e d'une fonction correspond √† la pente de sa droite tangente
en un point sp√©cifique.


Par exemple, voici le graphique d'une fonction, dessin√©e en noir, et une ligne tangente √† cette fonction, dessin√©e en rouge. La pente de la tangente est √©gale √† la d√©riv√©e de la fonction au point marqu√©.

""")
# \theta_j := \theta_j - \alpha\frac{\partial J}{\partial \theta_j}.
st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Tangent_to_a_curve.svg/214px-Tangent_to_a_curve.svg.png")



st.markdown(r"""
### L‚Äôalgorithme de descente du gradient
La m√©thode la plus simple pour minimiser la fonction d'erreur est l'algorithme de descente du gradient.
 Comme J est une fonction √† 2 variables ($\theta_0$ et $\theta_1$), on peut la repr√©senter en 3 dimensions par une surface d'√©quation
$z=J(X,Y)$.

L'id√©e de la m√©thode de descente du gradient est que pour trouver le minimum de la fonction $J$, 
c'est-√†-dire le point le plus bas de la surface, il suffit de partir d'un point quelconque de cette surface et de la parcourir en prenant toujours
 la direction qui ‚Äúdescend‚Äù le plus rapidement possible, c'est-√†-dire en avan√ßant ‚Äúface √† la pente‚Äù de la surface (en r√©alit√© la m√©thode ne fonctionne
  √† coup s√ªr que si la fonction n'a qu'un seul minimum local, ce qui est le cas de la fonction $J$).
""")

st.image("https://dridk.me/images/gradient_descendant/gradientDescent.jpg")


st.markdown(r"""
Math√©matiquement, cette direction est donn√©e par le gradient de la fonction $J$, qui est le vecteur dont les composantes 
   sont les d√©riv√©es partielles de la fonction par rapport √† chacune de ses variables:

   $$
\triangledown  J(\theta_0, \theta_1) = \binom{ \frac{\partial}{\partial \theta_0} J(\theta_0, \theta_1) }{ \frac{\partial}{\partial \theta_1} J(\theta_0, \theta_1) }   
   $$

L'algorithme consiste donc √† choisir des valeurs initiales quelconques pour $\theta_0$ et $\theta_1$, et √† ajuster ces param√®tres de
 mani√®re it√©rative en suivant la direction du gradient de $J$. Concr√®tement, on applique √† chaque it√©ration la formule suivante:

 $$
\left\{\begin{matrix}
\theta_0 =: \theta_0 - \alpha \frac{\partial}{\partial \theta_0} J(\theta_0, \theta_1) \\ 
\theta_1 =: \theta_1 - \alpha \frac{\partial}{\partial \theta_1} J(\theta_0, \theta_1)
\end{matrix}\right.
 $$


o√π $\alpha$ (hyper parameter) est appel√© le **taux d'apprentissage** (**learning rate**). 

Il faut ex√©cuter cette boucle jusqu'√† la convergence de l'algorithme, c'est-√†-dire jusqu'√† ce que les param√®tres $\theta_i$ ne varient (presque) plus.

#### Hyperparam√®tre : alpha
Alpha est un **hyperparam√®tre** qui est appel√© le **coefficient d'apprentissage**. 

Un hyperparam√®tre, c'est un param√®tre que l'algorithme ne peut pas apprendre par lui-m√™me. Il faut tester l'algorithme en faisant varier cet hyperparam√®tre.

Plus le coefficient d'apprentissage est √©lev√©, plus les pas entre deux mises √† jour de la fonction co√ªt seront importants. En modifiant ce param√®tre, 
nous sommes confront√©s √† un compromis entre la vitesse d'entra√Ænement et la convergence vers un solution satisfaisante.
L'impl√©mentation basique de cet algorithme s'appelle le **batch gradient descent**. √Ä chaque √©tape de calcul, il va calculer la d√©riv√©e partielle de toutes les observations ($m$). Cette m√©thode est donc longue pour les jeux de donn√©es tr√®s volumineux. 

### Descente du gradient : pour la r√©gression lin√©aire

Dans le cas de la r√©gression lin√©aire simple, la formule devient:

 $$
\left\{\begin{matrix}
\theta_0 =: \theta_0 - \alpha \frac{\partial}{\partial \theta_0} \frac{1}{m}\sum_{i=1}^m (h_{\theta}(x^{(i)}) - y^{(i)}) \\ 
\theta_1 =: \theta_1 - \alpha \frac{\partial}{\partial \theta_1} \frac{1}{m}\sum_{i=1}^m  (h_{\theta}(x^{(i)}) - y^{(i)})x^{(i)})
\end{matrix}\right.
 $$

En examinant cette formule, on voit bien que l'on fait d√©j√† du **Machine Learning**, et plus pr√©cis√©ment de l'**apprentissage supervis√©**,
 car le mod√®le apprend bien √† minimiser sa fonction d'erreur gr√¢ce aux donn√©es $x^{(i)}$ et $y^{(i)}$ de l'√©chantillon de r√©f√©rence.



""")

st.image("LR2.png")

st.markdown(r"""

Il existe une autre impl√©mentation qui est le **stochastic gradient descent**, au lieu de prendre toutes les observations √† chaque √©tape, 
l'algorithme va s√©lectionner au hasard une observation et calculer la d√©riv√©e partielle de celle-ci, 
en pratique cette m√©thode est assez efficace car elle impacte peu les performances et acc√©l√®re √©norm√©ment le temps d'entra√Ænement.

Outre ces deux versions, il existe des alternatives modernes (et assez complexes) √† la descente de gradient comme **L-BFGS, LMA**, etc.
""")

st.image("LR3.png")

st.markdown("""
La descente du gradient peut √™tre sujette √† la convergence dans des minimums locaux tandis que le probl√®me d'optimisation pos√© pour la 
r√©gression lin√©aire n'a qu'un seul minimum. **En d'autre mot la fonction co√ªt de la r√©gression lin√©aire est convexe**.

### Comment √©valuer la performance de notre mod√®le ?
La fonction co√ªt est un moyen de **mesurer la qualit√©** de notre algorithme.

Nous avons parl√© du MSE tout √† l'heure, _la moyenne des erreurs au carr√©_. Pour pouvoir l'interpr√©ter plus facilement, 
on peut prendre la racine carr√© de cette valeur pour avoir le **RMSE**.

Dans l'exemple pr√©c√©dent (prix en euros en fonction de la surface en m2) un RMSE √©gale √† 50, signifie qu'en moyenne notre algorithme se trompe de 50‚Ç¨. 


""")


st.image("LR4.png")


st.markdown(r"""

Se tromper de 50‚Ç¨ c'est bien ou pas ?  C'est difficile de r√©pondre objectivement √† cette question.

Cependant il existe une autre mesure : le coefficient de d√©termination ($R^2$).

L'avantage c'est que cette m√©trique est toujours comprise entre $0$ et $1$ . Le $R^2$ explique la proportion de la variance de $Y$ 
(variable √† expliquer comme le prix d'une maison) expliqu√©e par $X$ (variable explicative, le nombre de m¬≤)

$$
R^{2}=1-{SS_{\rm {res}} \over SS_{\rm {tot}}}
$$
o√π _sum of squares of residuals_:
$$
{\displaystyle SS_{\text{res}}=\sum _{i}(y_{i}-h_{\theta}(x_i))^{2}=\sum _{i}e_{i}^{2}\,}
$$
et _total sum of squares (proportional to the variance of the data)_:
$$
{\displaystyle SS_{\text{tot}}=\sum _{i}(y_{i}-{\bar {y}})^{2}}
$$


Plus cette m√©trique s'approche de 1, plus votre mod√©lisation sera qualitative.

Si on a un $R^2$ de 0,7 on peut affirmer la chose suivante : ‚ÄúNotre mod√®le explique 70% de la variance ou encore 70% de la variance du prix 
d'une maison est expliqu√©e par la surface en m2.‚Äù 


### D'o√π vient le coefficient de d√©termination $R^2$?
Le coefficient de Pearson $r$ ou coefficient de corr√©lation lin√©aire, mesure la liaison entre deux variables. Sa valeur peut varier en -1 et et 1.

Dans le cas d'une r√©gression lin√©aire simple, le coefficient de d√©termination est le carr√© du coefficient de corr√©lation. Clique [ici](https://statproofbook.github.io/P/slr-rsq) pour voir la preuve.


#### Abordez la r√©gression lin√©aire d‚Äôun point de vue statistique
Lien [ici](https://openclassrooms.com/fr/courses/4525326-realisez-des-modelisations-de-donnees-performantes/5754132-apprehendez-le-fonctionnement-de-la-regression-lineaire
)

___

# Exemple : Population and Profit 
""")
code = """
df = pd.read_csv("https://raw.githubusercontent.com/emaddar/Python_SAS_DEV_IA/main/Data/ex1data1.txt",
    header=None, names=["Population", "Profit"])
print(df.head())
"""
st.code(code, language="python")
df = pd.read_csv("https://raw.githubusercontent.com/emaddar/Python_SAS_DEV_IA/main/Data/ex1data1.txt",
    header=None, names=["Population", "Profit"])


st.dataframe(df.head())


code = """
df.plot(kind='scatter', x='Population', y='Profit')
plt.show()
"""

st.code(code, language="python")

fig = plt.figure()
x = df['Population']
y = df['Profit']
plt.scatter(x, y)
plt.xlabel("Population")
plt.ylabel("Profit")
# plt.plot(x, y)
st.pyplot(fig)



code = """
x = np.array(df.iloc[:, :1])
y = np.array(df.iloc[:, 1:])

# number of training examples
m = len(x)
print(f"m = {m}") # m = 97
# insert np.ones(m) to column 0
X = np.insert(x, 0, np.ones(m), axis=1)

# init theta with 0s
init_theta = np.zeros((2,1))

iterations = 3000
alpha = 0.01

print(f"x shape {X.shape}") # x shape (97, 2)
print(f"y shape = {y.shape}") # y shape = (97, 1)
print(f"init theta;shape = {init_theta.shape}") #  init theta;shape = (2, 1)



## Computing the cost function
def vectorized_compute_cost(X, y, theta):
    m = len(y)
    h = X @ theta
    diff = h - y
    res = 1 / (2 * m) * np.sum(np.square(diff)) 
    return res



## Gradient descent
def gradientDescent(X, y, theta, alpha, iterations):
    new_theta = theta.copy()
    costs = []
    for it in range(iterations):
        sum = np.zeros(new_theta.shape)
        m = len(X)
        for i in range(m):
            sum += (new_theta.T @ np.array([X[i]]).T - y[i]).item() * np.array([X[i]]).T
        new_theta -= alpha * 1 / (2 * m) * sum
        new_cost = vectorized_compute_cost(X, y, new_theta)
        costs.append(new_cost)
    return new_theta, costs

learned_theta, costs = gradientDescent(X, y, init_theta, alpha, iterations)

print(learned_theta) 
# [[-3.62996716]
# [ 1.16632977]]
print(costs[-5 : -1])
[4.483450511935242, 4.483438837935083, 4.483427184968944, 4.4834155529989275]
"""

st.code(code, language="python")

st.markdown(r"""
Donc :
$$
\hat{Profit} = -3.62996716 + 1.16632977* Population
$$
""")


code = """

# predict values for population sizes of 35,000 and 70,000
prediction1 = (learned_theta.T @ np.array([[1], [3.5]])).item()
prediction2 = (learned_theta.T @ np.array([[1], [7]])).item()
print("prediction 1: population 3.5, profit {}".format(prediction1)) 
# prediction 1: population 3.5, profit 0.4521870474418943

print("prediction 1: population 7, profit {}".format(prediction2)) 
# prediction 1: population 7, profit 4.5343412516298

"""
st.code(code, language="python")


x = np.array(df.iloc[:, :1])
y = np.array(df.iloc[:, 1:])

# number of training examples
m = len(x)

# insert np.ones(m) to column 0
X = np.insert(x, 0, np.ones(m), axis=1)

# init theta with 0s
init_theta = np.zeros((2,1))

iterations = 3000
alpha = 0.01




## Computing the cost function
def vectorized_compute_cost(X, y, theta):
    m = len(y)
    h = X @ theta
    diff = h - y
    res = 1 / (2 * m) * np.sum(np.square(diff)) 
    return res



## Gradient descent
def gradientDescent(X, y, theta, alpha, iterations):
    new_theta = theta.copy()
    costs = []
    for it in range(iterations):
        sum = np.zeros(new_theta.shape)
        m = len(X)
        for i in range(m):
            sum += (new_theta.T @ np.array([X[i]]).T - y[i]).item() * np.array([X[i]]).T
        new_theta -= alpha * 1 / (2 * m) * sum
        new_cost = vectorized_compute_cost(X, y, new_theta)
        costs.append(new_cost)
    return new_theta, costs

learned_theta, costs = gradientDescent(X, y, init_theta, alpha, iterations)


code = """

# visualize result
x_vector = np.linspace(df.Population.min(), df.Population.max(), 100)
x_constructed = np.insert(np.array([x_vector]), 0, np.ones(100), axis=0)
y_constructed = learned_theta.T @ x_constructed
y_vector = y_constructed.flatten()

fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8,16))
ax1.plot(x, y, "o", label="training data")
ax1.plot(x_vector, y_vector, "-", label="prediction")
ax1.legend()
ax1.set_title("Predicted Profit")
ax1.set_xlabel("Population")
ax1.set_ylabel("Profit")
ax2.plot(range(1, iterations + 1), costs, "-")
ax2.set_title("Cost")
ax2.set_xlabel("Iterations")
ax2.set_ylabel("Cost")
plt.show()
"""

# visualize result
x_vector = np.linspace(df.Population.min(), df.Population.max(), 100)
x_constructed = np.insert(np.array([x_vector]), 0, np.ones(100), axis=0)
y_constructed = learned_theta.T @ x_constructed
y_vector = y_constructed.flatten()

fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8,16))
ax1.plot(x, y, "o", label="training data")
ax1.plot(x_vector, y_vector, "-", label="prediction")
ax1.legend()
ax1.set_title("Predicted Profit")
ax1.set_xlabel("Population")
ax1.set_ylabel("Profit")
ax2.plot(range(1, iterations + 1), costs, "-")
ax2.set_title("Cost")
ax2.set_xlabel("Iterations")
ax2.set_ylabel("Cost")
st.pyplot(fig)